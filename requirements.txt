gym==0.19.0
torch==1.10.0
# We use a version of ray that includes modifications. This is the version of ray we built our changes on top of. By installing it first, we
# don't need to build the binary parts of ray from source ourselves. Instead, ray includes a script that combines the binary
# parts from the wheel with our modified python code.
ray[rllib,default]==1.13.0
protobuf==3.20  # Downgrade protobuf so the ray script mentioned above works
prometheus_client==0.13.1  # default version with ray-2.0.0 is broken
wandb==0.12.4
tqdm==4.62.1
# The exact tf version was not important in my experiments. However, saved policies can only be loaded with the same tf version, so it is
# important to keep it fixed
tensorflow==2.7.0
pyglet==1.5.19
open_spiel==1.0.1
pettingzoo[classic,atari]==1.12.0
autorom[accept-rom-license]==0.4.2
# mujoco-py<2.2,>=2.1
multiagent @ git+https://github.com/PavelCz/multiagent-particle-envs.git@be8e975910e0ca6d54232dd15b96d6ea04203870
# gym_compete @ git+https://github.com/PavelCz/multiagent-competition.git@v0.2.1
stable-baselines3==1.3.0
fire==0.4.0
python-dotenv==0.20.0
gin-config==0.5.0
