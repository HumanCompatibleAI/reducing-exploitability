gym==0.19.0
torch==1.10.0
# ray[rllib]==1.7
# The specific ray commit that I modified in ray-testbed
# ray[rllib] @ https://s3-us-west-2.amazonaws.com/ray-wheels/master/f5ac915ed5470ea5a68cd32b262ee857cbad9d17/ray-2.0.0.dev0-cp37-cp37m-manylinux2014_x86_64.whl
# The specific ray commit that I modified in ray pull request
# ray[rllib] @ https://s3-us-west-2.amazonaws.com/ray-wheels/master/6441335f5e8447ad07c0dbb7916e11aa43591876/ray-2.0.0.dev0-cp38-cp38-manylinux2014_x86_64.whl
# Ray 1.10
# ray[rllib] @ https://s3-us-west-2.amazonaws.com/ray-wheels/master/8b4cb45088a170e37d7d92c2e8a3dacddf67e1bc/ray-2.0.0.dev0-cp38-cp38-manylinux2014_x86_64.whl
wandb==0.12.4
tqdm==4.62.1
# The exact tf version was not important in my experiments. However, saved policies can only be loaded with the same tf version, so it is
# important to fix it
tensorflow==2.7.0
pyglet==1.5.19
open_spiel==1.0.1
pettingzoo[classic]==1.12.0
#griddly
#torch
mujoco-py<2.2,>=2.1
gym_compete @ git+https://github.com/PavelCz/multiagent-competition.git@v0.2.0
stable-baselines3==1.3.0
fire==0.4.0