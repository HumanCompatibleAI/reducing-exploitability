import os
import random
import time
from pathlib import Path

import gin
import ray
import wandb
from absl import app
from absl import flags
from dotenv import load_dotenv

from aprl_defense.base_logger import logger
from aprl_defense.training_managers.base_training_manager import (
    BaseTrainingManager,
)
from aprl_defense.training_managers.pbt_manager import PBTManager
from aprl_defense.training_managers.simple_training_manager import (
    SelfplayTrainingManager,
    AttackManager,
    SingleAgentTrainingManager,
)
from aprl_defense.trial.settings import TrialSettings, RLSettings

# The supported flags:
# -f to provide a gin config
# -p to overwrite gin parameters
# --override and --override_f to override the RLlib config only, either with a json string or a file respectively
flags.DEFINE_multi_string("f", None, "List of paths to the config files.")
flags.DEFINE_multi_string(
    "p", None, "Newline separated list of Gin parameter bindings."
)
flags.DEFINE_string("override", None, "Override RLlib config.")
flags.DEFINE_string("override_f", None, "Override RLlib config with a json file.")

FLAGS = flags.FLAGS


def main(argv):
    gin.parse_config_files_and_bindings(FLAGS.f, FLAGS.p)

    # Collect all the bindings from gin configurable params in one dictionary
    # Unfortunately I haven't found a way to do this other than manually
    # Only collects bindings that are changed from default
    binders = ["TrialSettings", "RLSettings", "selfplay", "attack", "pbt"]
    bindings = {}
    for binder in binders:
        next_bindings = gin.get_bindings(binder)
        bindings.update(next_bindings)

    # Determine out_path
    # Default is overwritten by cli param, is overwritten by environment variable
    # Env var is overwritten by dotenv file
    load_dotenv()
    out_path = os.environ.get("POLICY_DEFENSE_OUT", None)
    if out_path is None:
        trial_settings = TrialSettings()
    else:
        trial_settings = TrialSettings(
            out_path=out_path
        )  # Explicitly passing out_path overwrites both gin and default path
    rl_settings = RLSettings()

    out_path = trial_settings.out_path

    # Determine seed
    if trial_settings.seed is None:
        trial_settings.seed = random.randrange(
            2**32 - 1
        )  # Numpy has this as e max number for seed

    mode = trial_settings.mode

    # Determine run_name in wandb
    if trial_settings.run_name is None:
        run_name = f"{mode}_{rl_settings.alg}_{rl_settings.env}_{rl_settings.max_timesteps / 1_000_000}Mts"
    else:
        run_name = trial_settings.run_name

    # Whether to disable wandb logging
    wandb_mode = "online"
    if trial_settings.disable_log:
        wandb_mode = "disabled"

    # Init wandb
    wandb_dir = Path(out_path).expanduser().resolve() / "wandb"
    wandb_dir.mkdir(parents=True, exist_ok=True)
    wandb.init(
        project=trial_settings.wandb_project,
        name=run_name,
        config=bindings,
        mode=wandb_mode,
        group=trial_settings.wandb_group,
        dir=wandb_dir,  # Change wandb dir from the default
        job_type=mode,
        notes=trial_settings.description,
    )

    override = FLAGS.override
    override_f = FLAGS.override_f

    ray.init(local_mode=trial_settings.ray_local, num_cpus=trial_settings.num_cpus)

    training_manager: BaseTrainingManager
    if mode == "selfplay":
        training_manager = SelfplayTrainingManager(
            trial_settings,
            rl_settings,
            override,
            override_f,
        )
    elif mode == "single-agent":
        training_manager = SingleAgentTrainingManager(
            trial_settings, rl_settings, override, override_f
        )
    elif mode == "attack":
        training_manager = AttackManager(
            trial_settings, rl_settings, override, override_f
        )
    elif mode == "pbt":
        training_manager = PBTManager(trial_settings, rl_settings, override, override_f)
    else:  # Anything else is unsupported
        raise ValueError(f"Illegal argument for mode: {mode}")

    logger.info(f"Training with mode {mode}")
    time_start = time.time()
    training_manager.train()
    logger.info(f"Training of took {(time.time() - time_start) / 60} minutes")


if __name__ == "__main__":
    app.run(main)
