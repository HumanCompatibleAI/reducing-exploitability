train = {
    # --- Parallelism ---
    "num_workers": 1,
    "rollout_fragment_length": 25,
    "num_envs_per_worker": 1,
    "num_gpus": 0,
    "num_gpus_per_worker": 0,
    "horizon": 25,  # !IMPORTANT! Without this plotting results won't wor
    # Normalize actions is not available for multi-agent envs, at least according to this: https://github.com/ray-project/ray/issues/8518k
    # For me this problem only occured with SAC, DDPG
    "normalize_actions": False,
    "train_batch_size": 25,
    # "num_envs_per_worker": 4,
    # "sgd_minibatch_size": 256,
    # "rollout_fragment_length": 200,
}

eval_update = train

eval_config = {
    # --- Parallelism ---
    "num_workers": 3,
    "num_gpus": 0,
    "num_gpus_per_worker": 0,
    "horizon": 25,  # !IMPORTANT! Without this plotting results won't work
    "multiagent": {  # IMPORTANT, overwrite these settings before using config
        "policies": {},
        "policy_mapping_fn": None
    },
    "env_config": {
        "scenario_name": None,  # IMPORTANT, overwrite
    },
    # See explanation in train config
    "normalize_actions": False,
}
