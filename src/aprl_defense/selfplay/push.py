from ray import tune
from ray.tune.registry import register_env
from ray.rllib.env.wrappers.pettingzoo_env import PettingZooEnv
from pettingzoo.mpe import simple_push_v2
import supersuit

# Based on code from github.com/parametersharingmadrl/parametersharingmadrl

if __name__ == "__main__":
    # RDQN - Rainbow DQN
    # ADQN - Apex DQN
    def env_creator(args):
        env = simple_push_v2.env()
        # Padding to homogenize observations: PettingZoo requires same observation space dims for all agents
        env = supersuit.aec_wrappers.pad_observations(env)
        env = PettingZooEnv(env)
        return env

    env = env_creator({})
    register_env("push", env_creator)

    obs_space = env.observation_space
    act_spc = env.action_space
    policies = {agent: (None, obs_space, act_spc, {}) for agent in env.agents}

    tune.run(
        "PPO",
        stop={"episodes_total": 1000},
        checkpoint_freq=10,
        config={
            # Enviroment specific
            "env": "push",
            # General
            "num_gpus": 0,
            "num_workers": 2,
            # Method specific
            "multiagent": {
                "policies": policies,
                "policy_mapping_fn": (lambda agent_id: agent_id),
            },
            "render_env": False,
        },
    )
