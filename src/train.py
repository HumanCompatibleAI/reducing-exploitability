import argparse
import time

import ray

from aprl_defense.common.utils import trainer_map
from aprl_defense.pbt.fixed_iter_pbt import FixedIterPBTManager
from aprl_defense.pbt.fair_pbt import FairPBTManager
from aprl_defense.pbt_scheduler import random_scheduler, random_choice_scheduler
from aprl_defense.training_manager import FinetuneManager, NormalTrainingManager
import wandb


def main():
    args = parse_args()
    out_path = args.out_path
    alg = args.alg
    timesteps = args.max_timesteps
    checkpoint_freq = args.checkpoint_freq
    mode = args.mode

    if args.name is None:
        run_name = f'{mode}_{alg}'
    else:
        run_name = args.name

    wandb_mode = 'online'

    if args.disable_log:
        wandb_mode = 'disabled'

    project = "ap-defense-2"

    wandb.init(project=project, name=run_name, config=args, mode=wandb_mode)
    train(mode,
          out_path,
          alg,
          timesteps,
          checkpoint_freq,
          victim_path=args.victim_path,
          cycle_ops=args.cycle_ops,
          num_ops=args.num_ops,
          harden_id=args.harden_id,
          adversary_id=args.adv_id,
          iter_steps=args.iter_steps,
          override=args.override
          )


def train(mode,
          out_path,
          alg,
          timesteps,
          checkpoint_freq,
          local_mode=False,
          victim_path="",
          cycle_ops=False,
          num_ops=10,
          harden_id=0,
          adversary_id=1,
          iter_steps=None,
          override=None):
    ray.init(local_mode=local_mode)
    if mode == 'normal':
        training_manager = NormalTrainingManager(log_dir=out_path,
                                                 alg=alg,
                                                 max_timesteps=timesteps,
                                                 checkpoint_freq=checkpoint_freq,
                                                 override=override)
    elif mode == 'finetune':
        training_manager = FinetuneManager(log_dir=out_path,
                                           alg=alg,
                                           max_timesteps=timesteps,
                                           checkpoint_freq=checkpoint_freq,
                                           override=override,
                                           victim_path=victim_path,
                                           adversary_id=adversary_id)
    elif mode == 'pbt':
        training_manager = FixedIterPBTManager(log_dir=out_path,
                                               alg=alg,
                                               max_timesteps=timesteps,
                                               checkpoint_freq=checkpoint_freq,
                                               override=override,
                                               main_id=harden_id,
                                               scheduler_func=random_scheduler,
                                               iter_steps=iter_steps)
    elif mode == 'improved-pbt':
        training_manager = FairPBTManager(log_dir=out_path,
                                          alg=alg,
                                          max_timesteps=timesteps,
                                          checkpoint_freq=checkpoint_freq,
                                          override=override,
                                          main_id=harden_id,
                                          scheduler_func=random_choice_scheduler,
                                          cycle_agents=cycle_ops,
                                          num_ops=num_ops,
                                          iter_steps=iter_steps)

    else:  # Anything else is unsupported
        raise ValueError(f'Illegal argument for mode: {mode}')

    print(f'Training with mode {mode}')
    time_start = time.time()
    training_manager.train()
    print(f"Training of {alg} took {(time.time() - time_start) / 60} minutes")


def parse_args():
    parser = argparse.ArgumentParser("Adversarial Policy on MADDPG")
    parser.add_argument('--victim-path', type=str)
    parser.add_argument('--mode', choices=['finetune', 'pbt', 'normal', 'eval', 'improved-pbt'],
                        default='normal')
    parser.add_argument('--out-path', type=str, default='~/ray_results')
    parser.add_argument('--alg', choices=trainer_map.keys(), default='ppo')
    parser.add_argument('--max-timesteps', type=int, default=1_500_000)
    parser.add_argument('--checkpoint-freq', type=int, default=250000)
    parser.add_argument('--disable-log', action='store_true')
    parser.add_argument('--cycle-ops', action='store_true')
    parser.add_argument('--num-ops', type=int, default=10)
    parser.add_argument('--name', type=str, default=None)
    parser.add_argument('--harden-id', type=int, default=0)
    parser.add_argument('--adv-id', type=int, default=1)
    parser.add_argument('--iter-steps', type=int, default=2500)
    parser.add_argument('--override', type=str, default=None)

    return parser.parse_args()


if __name__ == '__main__':
    main()
