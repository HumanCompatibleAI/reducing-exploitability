import numpy as np

from aprl_defense.eval import multi_eval

checkpoints_folder_main = "/scratch/pavel/out/8-self-play/"

main_alg = 'ppo'

main_folders = ['2qjb9qso',
                '1vqsnfzs',
                '2nqomi4d',
                '28p7l83y',
                '3juxjbos',
                ]
num_steps = 100000
local_mode = False

print(f"folders: {main_folders}")

rewards_0 = []
rewards_1 = []

runs = 0
for folder_0 in main_folders:
    for folder_1 in main_folders:
        if folder_0 != folder_1:
            runs += 1
            results = multi_eval(agent_algs=[main_alg, main_alg],
                                 agent_paths=[checkpoints_folder_main + folder_0, checkpoints_folder_main + folder_1],
                                 agent_to_policy_name=['policy_0', 'policy_1'],
                                 num_steps=num_steps,
                                 render=False,
                                 local_mode=local_mode)
            rewards_0.append(results['mean_rewards'][0])
            rewards_1.append(results['mean_rewards'][1])

print(f'Performed {runs} runs')

mean_0 = np.mean(rewards_0)
mean_1 = np.mean(rewards_1)

std_0 = np.std(rewards_0)
std_1 = np.std(rewards_1)

print('===== FINAL RESULTS =====')

print(f'mean_0: {mean_0:.3f}')
print(f'mean_1: {mean_1:.3f}')
print(f'std_0: {std_0:.3f}')
print(f'std_1: {std_1:.3f}')
