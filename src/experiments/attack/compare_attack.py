from pathlib import Path

import numpy as np
import ray

import aprl_defense.configs.eval

from aprl_defense.common.io import get_checkpoint_file, restore_trainer_from_path
from aprl_defense.common.train import init_env
from aprl_defense.common.utils import trainer_cls_from_str
from aprl_defense.eval import multi_eval

checkpoints_folder_main = "/scratch/pavel/out/9-comm/"

main_alg = 'ppo'

agent_algs = [main_alg, main_alg]

scenario_name = 'simple_push_comm'

# (attack_folder, victim_folder, adv_id)

main_folders = [  # Simple push with communication on rnn
    ('11l3cjqo', '34aphnzq', 1),
    ('13isn61o', '2uhlxvzu', 1),
    ('4ao1bvsf', '3h90dkz7', 1),
    ('omln7ecq', '29wzrlx7', 1),
    ('2u6pey6u', '2xafftpw', 1),
    ('14na2q7h', '1oct0lga', 1),
    ('13g3pubo', '3b4sol4r', 1),
    ('2e9hmn6m', '5hwd3qsd', 1),
    ('2vx9ebia', '2qvmbqhu', 1),
    ('20cl0ca7', '1eefhkpm', 1),

    ('1ltio1yb', '34aphnzq', 1),
    ('3gxesqqo', '2uhlxvzu', 1),
    ('aqiv65qo', '3h90dkz7', 1),
    ('24ry896y', '29wzrlx7', 1),
    ('2jmmrj7b', '2xafftpw', 1),
    ('2rqf4o31', '1oct0lga', 1),
    ('1rzmd4bc', '3b4sol4r', 1),
    ('3dir3nlx', '5hwd3qsd', 1),
    ('2o2liwgt', '2qvmbqhu', 1),
    ('1mx8criv', '1eefhkpm', 1),

    ('kat0fq2y', '34aphnzq', 0),
    ('33nfvr39', '2uhlxvzu', 0),
    ('o9f4t6a5', '3h90dkz7', 0),
    ('divlr9e8', '29wzrlx7', 0),
    ('x57t2pey', '2xafftpw', 0),
    ('2t1nb9go', '1oct0lga', 0),
    ('2ildj4ts', '3b4sol4r', 0),
    ('22q9a4yf', '5hwd3qsd', 0),
    ('2rjazntb', '2qvmbqhu', 0),
    ('1kzjplgv', '1eefhkpm', 0),

    ('2jg8bx4a', '34aphnzq', 0),
    ('r5a3pclg', '2uhlxvzu', 0),
    ('3ohosp9d', '3h90dkz7', 0),
    ('2t42xav0', '29wzrlx7', 0),
    ('3h8f8iy9', '2xafftpw', 0),
    ('28dfc9sq', '1oct0lga', 0),
    ('1jxefvh9', '3b4sol4r', 0),
    ('ddjt234q', '5hwd3qsd', 0),
    ('1h6lwtym', '2qvmbqhu', 0),
    ('2zah5at6', '1eefhkpm', 0),
]

# main_folders = [('2e5kpmzh', '2qjb9qso', 1),  # Normal simple_push
#                 ('3mr4nfyr', '2qjb9qso', 0),
#                 ('1v90kucq', '1vqsnfzs', 1),
#                 ('2wzj0fg1', '1vqsnfzs', 0),
#                 ('m86ujamn', '2nqomi4d', 1),
#                 ('2ekbotg9', '2nqomi4d', 0),
#                 ('nqfz9f2z', '28p7l83y', 1),
#                 ('3417h6oy', '28p7l83y', 0),
#                 ('gq1dr38j', '3juxjbos', 0),
#                 ('td0pitwo', '3juxjbos', 1),
#                 ('s1yjn93z', '3spmkqei', 0),
#                 ('1ygtoxzx', '3spmkqei', 1),
#                 ('2d6c75zn', '26m8i5ur', 1),
#                 ('2cw6d2ht', '26m8i5ur', 0),
#                 ('o76j020j', '27bvd59k', 1),
#                 ('2bhbx53i', '27bvd59k', 1),
#                 ('eygxt41f', '1k92hc8r', 0),
#                 ('t0zsjp1s', '1k92hc8r', 0),
#                 ('3t0h4p6o', '27bg537a', 0),
#                 ('udi9nso1', '27bg537a', 1),
#                 ]
num_steps = 50000
local_mode = False

print(f"folders: {main_folders}")
#
# ray.init(local_mode=local_mode)
# # Make sure all files exist as the should
# for (attack_folder, victim_folder, adv_id) in main_folders:
#     if adv_id == 1:
#         agent_paths = [checkpoints_folder_main + victim_folder, checkpoints_folder_main + attack_folder]
#     else:  # adv_id == 0:
#         assert adv_id == 0
#         agent_paths = [checkpoints_folder_main + attack_folder, checkpoints_folder_main + victim_folder]
#
#     one_hot_agents = [is_one_hot_agent(agent_alg) for agent_alg in agent_algs]
#
#     # Register env here, so it can be found when loading the policy
#     env = init_env(env_name="mpe", scenario_name=scenario_name, max_steps=25, one_hot_agents=one_hot_agents)
#
#     trainer_classes = [trainer_cls_from_str(agent_alg) for agent_alg in agent_algs]
#     for i, path in enumerate(agent_paths):
#
#         checkpoint_file = get_checkpoint_file(path)
#
#         trainer = restore_trainer_from_path(Path(checkpoint_file),
#                                             scenario_name,
#                                             trainer_classes[i],
#                                             config_update=aprl_defense.configs.eval.eval_update)
# ray.shutdown()
#
# print('All policies were found')
# Actual Evaluation

rewards_0 = []
rewards_1 = []

runs = 0
for (attack_folder, victim_folder, adv_id) in main_folders:
    runs += 1
    if adv_id == 1:
        agent_paths = [checkpoints_folder_main + victim_folder, checkpoints_folder_main + attack_folder]
    elif adv_id == 0:
        agent_paths = [checkpoints_folder_main + attack_folder, checkpoints_folder_main + victim_folder]
    else:
        raise ValueError(f'Unsupported adv_id={adv_id}')
    results = multi_eval(agent_algs=[main_alg, main_alg],
                         agent_paths=agent_paths,
                         agent_to_policy_name=['policy_0', 'policy_1'],
                         num_steps=num_steps,
                         render=False,
                         local_mode=local_mode,
                         scenario_name=scenario_name)
    if adv_id == 0:
        rewards_0.append(results['mean_rewards'][0])
    elif adv_id == 1:
        rewards_1.append(results['mean_rewards'][1])
    else:
        pass

print(f'Performed {runs} runs')
print(rewards_0)
print(rewards_1)

mean_0 = np.mean(rewards_0)
mean_1 = np.mean(rewards_1)

std_0 = np.std(rewards_0)
std_1 = np.std(rewards_1)

print('===== FINAL RESULTS =====')

print(f'mean_0: {mean_0:.3f}')
print(f'mean_1: {mean_1:.3f}')
print(f'std_0: {std_0:.3f}')
print(f'std_1: {std_1:.3f}')
