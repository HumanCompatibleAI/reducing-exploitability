import gym
import numpy as np
from ray.rllib import MultiAgentEnv
from ray.rllib.examples.env.mock_env import MockEnv


class AsymmetricMultiAgent(MultiAgentEnv):
    """Env of N independent agents, each of which exits after 25 steps."""

    metadata = {
        "render.modes": ["rgb_array"],
    }

    def __init__(self):
        num = 2
        super().__init__()
        self.agents = [MockEnv(25) for _ in range(num)]
        self.agent_ids = set(range(num))
        self.dones = set()
        self.observation_space = gym.spaces.Dict(spaces={i: gym.spaces.Box(low=np.array([-1, -1]), high=np.array([1, 1])) for i in self.agent_ids})
        self.action_space = gym.spaces.Discrete(num)
        self.resetted = False

    def reset(self):
        self.resetted = True
        self.dones = set()
        return {i:  np.zeros((2, 1)) for i, a in enumerate(self.agents)}

    def step(self, action_dict):
        obs, rew, done, info = {}, {}, {}, {}
        for i, action in action_dict.items():
            _, rew[i], done[i], info[i] = self.agents[i].step(action)
            obs[i] = np.zeros((2, 1))
            if done[i]:
                self.dones.add(i)
        done["__all__"] = len(self.dones) == len(self.agents)
        return obs, rew, done, info

    def render(self, mode="rgb_array"):
        # Just generate a random image here for demonstration purposes.
        # Also see `gym/envs/classic_control/cartpole.py` for
        # an example on how to use a Viewer object.
        return np.random.randint(0, 256, size=(200, 300, 3), dtype=np.uint8)
