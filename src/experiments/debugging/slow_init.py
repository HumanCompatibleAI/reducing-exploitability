import time

import gym
import ray
from ray.rllib.agents.dqn import DQNTrainer
from ray.rllib.agents.ppo import PPOTrainer
from ray.rllib.examples.env.multi_agent import MultiAgentCartPole
from ray.tune import register_env

ray.init()

num_policies = 30
num_workers = 10

# Simple environment with 4 independent cartpole entities
register_env("multi_agent_cartpole",
             lambda _: MultiAgentCartPole({"num_agents": num_policies}))
single_dummy_env = gym.make("CartPole-v0")
obs_space = single_dummy_env.observation_space
act_space = single_dummy_env.action_space

policies = {str(i): (None, obs_space, act_space, {}) for i in range(num_policies)}

policy_mapping_fn = str

print('==================')
print(f'num_policies = {num_policies}')
print(f'num_workers {num_workers}')
config = {
    'framework': 'tf',
    'num_workers': num_workers,
    "multiagent": {
        "policies": policies,
        "policy_mapping_fn": policy_mapping_fn,
        "policies_to_train": None,  # All
    }
}
start = time.time()
ppo_trainer = PPOTrainer(
    env="multi_agent_cartpole",
    config=config)

print(f"PPO init took {time.time() - start} seconds")

# start = time.time()
# dqn_trainer = DQNTrainer(
#     env="multi_agent_cartpole",
#     config=config)
#
# print(f"DQN init took {time.time() - start} seconds")
